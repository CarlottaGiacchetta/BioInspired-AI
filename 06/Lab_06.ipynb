{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "042d10dd",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "## Goal\n",
    "The goal of this lab is to familiarize yourself with Particle Swarm Optimization and study the effect of parametrization on the algorithmic performance.\n",
    "\n",
    "Note once again that, unless otherwise specified, in this module's exercises we will use real-valued genotypes and that the aim of the algorithms will be to *minimize* the fitness function $f(\\mathbf{x})$, i.e. lower values correspond to a better fitness!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a555238",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "As a first exercise, we will run a simple 2D Boids simulator, based on the Reynolds' flocking rules we have seen during the lectures. Although this exercise is not strictly related to PSO, it provides a good source of inspiration (and intuition) on how PSO works. \n",
    "\n",
    "The simulator allows you to change various aspects of the simulation, specifically the total number of boids, the number of neighbors whose information is collected by each boid (to determine cohesion, alignment, and separation), and the relative weights of each of the 3 flocking rules (behavior coefficients). Spend some time with the simulator, and try different simulation configurations.\n",
    "\n",
    "To help you figure out the behavior of the boids, you can find below the implementation of the `boid` class extracted from the source code of the simulator. In particular, check the `update` method.\n",
    "\n",
    "- What is the effect of each behavior coefficient?\n",
    "\n",
    "Cohesion: This rule encourages each boid to move towards the center of mass of its neighboring boids. When the cohesion coefficient is higher, the boids are more likely to group together and move as a cohesive unit, almost like they are attracted to stay close to one another.\n",
    "\n",
    "Alignment: This rule causes the boids to align their direction of movement with the average direction of their nearby boids. The higher the alignment coefficient, the more closely the boids will match the direction of their neighbors, which helps them stay coordinated and move in the same direction, preventing them from scattering in different ways.\n",
    "\n",
    "Separation: This rule ensures that the boids don’t get too close to one another, maintaining a safe distance to avoid crowding or collisions. A higher separation coefficient increases their tendency to keep space between each other, which prevents them from clustering too tightly or crashing into one another.\n",
    "\n",
    "- Which combination of coefficients leads to the most ``natural'' flock behavior? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8bdc7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.11.7)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "1,1.5,1 [50, 1, 1.5, 1]\n",
      "1,1.5,1\n",
      "1,1.5,0.5 [50, 1, 1.5, 0.5]\n",
      "1,1.5,0.5\n",
      "1,0.5,1 [50, 1, 0.5, 1]\n",
      "1,0.5,1\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from utils.utils_06.main import run\n",
    "from utils.utils_06.rules import Rules\n",
    "import os\n",
    "\n",
    "class Boid(Rules):\n",
    "    def __init__(self, screen_width, screen_height):\n",
    "        super().__init__(screen_width, screen_height)\n",
    "        self.position = Vector2(random.uniform(0, screen_width), random.uniform(0, screen_height))\n",
    "        self.velocity = Vector2(random.uniform(-1, 1), random.uniform(-1, 1))\n",
    "        self.radius = 100\n",
    "\n",
    "    # Draw the boid\n",
    "    def draw(self, screen):\n",
    "        pg.draw.circle(screen,'red', (int(self.position.x), int(self.position.y)), 5)\n",
    "\n",
    "    ### Update the position of the boid\n",
    "    def update(self, boids, ALIGNMENT, COHESION, SEPARATION):\n",
    "        \n",
    "        ### Weights of the rules\n",
    "\n",
    "        ### Neighbors in range\n",
    "        n = Rules.neighbors(self, boids)\n",
    "\n",
    "        ### Rules to follow\n",
    "        alignment = ALIGNMENT * Rules.match_velocity(self, n)\n",
    "        cohesion = COHESION * Rules.fly_towards_center(self, n)\n",
    "        separation_from_boids = SEPARATION * Rules.keep_distance_away(self, n, 9)\n",
    "        \n",
    "        # Update velocity \n",
    "        self.velocity += alignment + cohesion + separation_from_boids\n",
    "\n",
    "        # Limit the speed of the boids\n",
    "        self.velocity.scale_to_length(5)\n",
    "\n",
    "        # Update position\n",
    "        self.position += self.velocity\n",
    "        \n",
    "        # Wrap the position of the boids\n",
    "        Rules.bound_position(self)\n",
    "\n",
    "        \n",
    "\"\"\"\n",
    "-------------------------------------------------------------------------\n",
    "Edit this part to do the exercises\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "runs = {\n",
    "    'base': [50,    0.5,    0.5,    0.5],\n",
    "    'alligment more': [50,    1,    0.5,    0.5],\n",
    "    'cohesion more': [50,    0.5,    1,    0.5],\n",
    "    'separation more': [50,    0.5,    0.5,    1],\n",
    "    'boids more': [100,    0.5,    0.5,    0.5],\n",
    "    #'1,1.5,1': [50,    1,    1.5,    1],\n",
    "    #'1,1.5,0.5': [50,    1,    1.5,    0.5],\n",
    "    '1,0.5,1': [50,    1,    0.5,    1],\n",
    "\n",
    "}\n",
    "for run in runs:\n",
    "    print(run, runs[run])\n",
    "    num_boids = runs[run][0]   # advice: for graphical reasons avoid to use num_boids > 400\n",
    "    alignment = runs[run][1]  #default: 0.5\n",
    "    cohesion = runs[run][2]   # default: 0.5\n",
    "    separation = runs[run][3] # default: 0.5\n",
    "    title=run\n",
    "    # make sure you are calling the right version of python in the process below\n",
    "   \n",
    "    os.popen(f'python utils/utils_06/main.py {num_boids} {alignment} {cohesion} {separation} {title}').read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4d4319",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "In this exercise we will perform a comparative analysis of the results of Genetic Algorithm (as seen in Lab 2), Evolution Strategies (as seen in Lab 3) and Particle Swarm Optimization. \n",
    "The script will perform a single run of GA, ES and PSO, on one of the benchmark functions we have seen in the previous labs. As usual, the algorithm parametrization is shown in the code and can be easily modified.\n",
    "\n",
    "Questions:\n",
    "-  What kind of behavior does PSO have on different benchmark functions (change the parameter `args[\"problem_class\"]` to try at least a couple of functions), in comparison with the EAs? Does it show better or worse results? Does it converge faster or not?\n",
    "\n",
    "For some functions, PSO may be more efficient due to its nature of exploring the search space through particle velocities rather than relying on mutation/crossover strategies.\n",
    "PSO converges more quickly on simpler functions (like Sphere) but might struggle more with complex multimodal functions (like Rastrigin or Ackley) compared to GA and ES, depending on the tuning of the parameters.\n",
    "\n",
    "- What happens if you run the script multiple times? Do the various algorithms (and especially PSO) show consistent behavior?\n",
    "\n",
    "- Increase the problem dimensionality (`num_vars`, by default set to 2), e.g. to 10 or more. What do you observe in this case?\n",
    "\n",
    "Increasing the dimensionality of the problem makes optimization significantly harder for all algorithms, but the effect is more pronounced for GA and ES. PSO generally shows better robustness when dealing with higher-dimensional problems, though its performance also deteriorates, particularly on complex functions like Schwefel and Ackley. In high-dimensional spaces, it’s crucial to fine-tune the algorithms and possibly use more sophisticated approaches to prevent them from getting stuck in local optima.\n",
    "\n",
    "-  Change the population size (by changing`args[\"pop_size\"]`, by default set to 50) and the number of generations (by changing `args[\"max_generations\"]`, by default set to 100), such that their product is fixed (e.g. $25 \\times 200$, $100 \\times 50$, etc.). Try two or three different combinations and observe the behavior of the three different algorithms. What do you observe in this case? Is it better to have smaller/larger populations or a smaller/larger number of generations? Why?\n",
    "\n",
    "Impact of More Generations (Smaller Population):\n",
    "\n",
    "Across all functions, more generations with a smaller population (25 × 200) generally yield better results, particularly for PSO and ES. The added time for exploration allows the algorithms to refine their solutions and avoid premature convergence, especially on more complex landscapes like Ackley and Rosenbrock.\n",
    "PSO benefits the most from this configuration, improving significantly on Ackley and Rosenbrock. This indicates that PSO’s swarm-based exploration thrives when it has more generations to explore the search space, even with a smaller population.\n",
    "Impact of Larger Population (Fewer Generations):\n",
    "\n",
    "Larger populations with fewer generations (100 × 50) tend to produce worse results for all three algorithms. The algorithms are likely able to explore the search space more broadly at first, but the limited number of generations prevents them from fine-tuning and improving the solutions over time. This is especially true for ES and PSO, which perform particularly poorly on Rosenbrock and Ackley with this configuration.\n",
    "GA also struggles in this configuration, showing that more generations are critical for its crossover and mutation mechanisms to effectively improve solutions.\n",
    "Algorithm-Specific Trends:\n",
    "\n",
    "GA: Tends to perform better with more generations, as it relies on evolutionary processes that take time to fine-tune solutions. GA suffers the most when generations are limited (e.g., 100 × 50).\n",
    "ES: Performs well with more generations and suffers heavily with fewer generations, particularly on complex landscapes like Rosenbrock and Schwefel. It often struggles to escape local optima when generations are limited.\n",
    "PSO: Shows significant improvement when given more generations, suggesting that its exploration-exploitation balance is more effective when allowed to run for a longer period. It performs the worst with fewer generations, as it cannot fully explore the search space.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ab5c21",
   "metadata": {},
   "source": [
    "#### multiple runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51d85b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- Statistics for Sphere ---\n",
      "GA:    Mean = 0.0000139, Standard Deviation = 0.0000118\n",
      "ES:    Mean = 0.0000000, Standard Deviation = 0.0000000\n",
      "PSO:   Mean = 0.0000000, Standard Deviation = 0.0000000\n",
      "\n",
      "\n",
      "--- Statistics for Rosenbrock ---\n",
      "GA:    Mean = 0.0021399, Standard Deviation = 0.0018857\n",
      "ES:    Mean = 0.0113013, Standard Deviation = 0.0301609\n",
      "PSO:   Mean = 0.0002662, Standard Deviation = 0.0003608\n",
      "\n",
      "\n",
      "--- Statistics for Ackley ---\n",
      "GA:    Mean = 0.0078774, Standard Deviation = 0.0050192\n",
      "ES:    Mean = 0.0000005, Standard Deviation = 0.0000003\n",
      "PSO:   Mean = 0.0000006, Standard Deviation = 0.0000005\n",
      "\n",
      "\n",
      "--- Statistics for Schwefel ---\n",
      "GA:    Mean = 0.0997073, Standard Deviation = 0.2989936\n",
      "ES:    Mean = 57.2454928, Standard Deviation = 75.1412790\n",
      "PSO:   Mean = 23.6879176, Standard Deviation = 47.3752213\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from pylab import *\n",
    "import sys\n",
    "from inspyred import ec\n",
    "from inspyred import benchmarks\n",
    "\n",
    "\n",
    "from utils.utils_06.inspyred_utils import NumpyRandomWrapper\n",
    "import utils.utils_06.ga as ga\n",
    "import utils.utils_06.es as es\n",
    "import utils.utils_06.pso as pso\n",
    "\"\"\"\n",
    "-------------------------------------------------------------------------\n",
    "Edit this part to do the exercises\n",
    "\"\"\"\n",
    "runs = {\n",
    "    'Sphere': benchmarks.Sphere,\n",
    "    'Rosenbrock': benchmarks.Rosenbrock,\n",
    "    'Ackley': benchmarks.Ackley,\n",
    "    'Schwefel': benchmarks.Schwefel\n",
    "\n",
    "}\n",
    "\n",
    "num_repeats = 10  # Number of times to repeat each configuration\n",
    "ga_fitnesses = []\n",
    "es_fitnesses = []\n",
    "pso_fitnesses = []\n",
    "\n",
    "args = {}\n",
    "num_vars = 2 # Number of dimensions of the search space\n",
    "# common parameters\n",
    "args[\"max_generations\"] = 100 # Number of generations\n",
    "args[\"pop_size\"] = 50 # population size\n",
    "# parameters for the GA\n",
    "args[\"gaussian_stdev\"] = 0.5 # Standard deviation of the Gaussian mutations\n",
    "args[\"mutation_rate\"] = 0.5 # fraction of loci to perform mutation on\n",
    "args[\"tournament_size\"] = 2\n",
    "args[\"num_elites\"] = 1 # number of elite individuals to maintain in each gen\n",
    "# parameters for the ES\n",
    "args[\"num_offspring\"] = 100 #lambda\n",
    "args[\"sigma\"] = 1.0 # default standard deviation\n",
    "args[\"strategy_mode\"] = es.INDIVIDUAL # es.GLOBAL, es.INDIVIDUAL, None\n",
    "args[\"mixing_number\"] = 1 #rho\n",
    "# parameters for the PSO\n",
    "args[\"topology\"] = pso.STAR #pso.RING, pso.STAR\n",
    "args[\"neighborhood_size\"] = 5   #used only for the ring topology\n",
    "args[\"inertia\"] = 0.5\n",
    "args[\"cognitive_rate\"] = 2.1\n",
    "args[\"social_rate\"] = 2.1\n",
    "\n",
    "\n",
    "for run in runs:\n",
    "    # Reset fitness results for the current configuration\n",
    "    ga_fitnesses.clear()\n",
    "    es_fitnesses.clear()\n",
    "    pso_fitnesses.clear()\n",
    "\n",
    "    # the problem class\n",
    "    args[\"problem_class\"] = runs[run]\n",
    "\n",
    "    for i in range(num_repeats):\n",
    "\n",
    "        display = False # Plot initial and final populations\n",
    "\n",
    "        rng = NumpyRandomWrapper()\n",
    "        # Run GA\n",
    "        args[\"fig_title\"] = \"GA\"\n",
    "        best_individual, best_fitness, final_pop = ga.run_ga(rng,num_vars=num_vars,\n",
    "                                                display=display,use_log_scale=True,\n",
    "                                                **args)\n",
    "        ga_fitnesses.append(best_fitness)\n",
    "        #print(f\"Best GA fitness in run {i+1}: {best_fitness}\")\n",
    "        # Run ES\n",
    "        args[\"fig_title\"] = \"ES\"\n",
    "        best_individual, best_fitness, final_pop = es.run_es(rng,num_vars=num_vars,\n",
    "                                                    display=display,use_log_scale=True,\n",
    "                                                    **args)\n",
    "        es_fitnesses.append(best_fitness)\n",
    "        #print(f\"Best ES fitness in run {i+1}: {best_fitness}\")\n",
    "        # Run PSO\n",
    "        args[\"fig_title\"] = \"PSO\"\n",
    "        best_individual, best_fitness, final_pop = pso.run_pso(rng,num_vars=num_vars,\n",
    "                                                    display=display,use_log_scale=True,\n",
    "                                                    **args)\n",
    "        pso_fitnesses.append(best_fitness)\n",
    "        #print(f\"Best PS= fitness in run {i+1}: {best_fitness}\")\n",
    "\n",
    "        ioff()\n",
    "        show()\n",
    "    # Calculate and display mean and variance for each algorithm\n",
    "    print(f\"\\n\\n--- Statistics for {run} ---\")\n",
    "    print(f\"GA:    Mean = {np.mean(ga_fitnesses):.7f}, Standard Deviation = {np.std(ga_fitnesses):.7f}\")\n",
    "    print(f\"ES:    Mean = {np.mean(es_fitnesses):.7f}, Standard Deviation = {np.std(es_fitnesses):.7f}\")\n",
    "    print(f\"PSO:   Mean = {np.mean(pso_fitnesses):.7f}, Standard Deviation = {np.std(pso_fitnesses):.7f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e29b2ac",
   "metadata": {},
   "source": [
    "#### problem dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a13fd7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "num_vars basic Sphere [<class 'inspyred.benchmarks.Sphere'>, 2]\n",
      "Best GA fitness : 5.102534098785902e-06\n",
      "Best ES fitness : 3.418557050742053e-15\n",
      "Best PS fitness: 4.515795860184033e-15\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "num_vars more Sphere [<class 'inspyred.benchmarks.Sphere'>, 10]\n",
      "Best GA fitness : 0.39668095049764274\n",
      "Best ES fitness : 0.02572489055550019\n",
      "Best PS fitness: 0.059650839821255776\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "num_vars basic Rosenbrock [<class 'inspyred.benchmarks.Rosenbrock'>, 2]\n",
      "Best GA fitness : 0.000774842023694006\n",
      "Best ES fitness : 0.04234872146363992\n",
      "Best PS fitness: 4.472513548816972e-05\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "num_vars more Rosenbrock [<class 'inspyred.benchmarks.Rosenbrock'>, 10]\n",
      "Best GA fitness : 31.75568451827765\n",
      "Best ES fitness : 28.109154387913993\n",
      "Best PS fitness: 203.51909688058743\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "num_vars basic Ackley [<class 'inspyred.benchmarks.Ackley'>, 2]\n",
      "Best GA fitness : 0.008974675375647667\n",
      "Best ES fitness : 6.178820091129467e-07\n",
      "Best PS fitness: 1.0978236208991632e-06\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "num_vars more Ackley [<class 'inspyred.benchmarks.Ackley'>, 10]\n",
      "Best GA fitness : 1.9205739546142984\n",
      "Best ES fitness : 7.939871850568466\n",
      "Best PS fitness: 3.774993869855227\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "num_vars basic Schwefel [<class 'inspyred.benchmarks.Schwefel'>, 2]\n",
      "Best GA fitness : 2.5595775014153332e-05\n",
      "Best ES fitness : 2.545513257246057e-05\n",
      "Best PS fitness: 2.7811956897494383e-05\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "num_vars more Schwefel [<class 'inspyred.benchmarks.Schwefel'>, 10]\n",
      "Best GA fitness : 374.3548040782548\n",
      "Best ES fitness : 1526.590809317183\n",
      "Best PS fitness: 854.8376106406836\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from pylab import *\n",
    "import sys\n",
    "from inspyred import ec\n",
    "from inspyred import benchmarks\n",
    "\n",
    "\n",
    "from utils.utils_06.inspyred_utils import NumpyRandomWrapper\n",
    "import utils.utils_06.ga as ga\n",
    "import utils.utils_06.es as es\n",
    "import utils.utils_06.pso as pso\n",
    "\"\"\"\n",
    "-------------------------------------------------------------------------\n",
    "Edit this part to do the exercises\n",
    "\"\"\"\n",
    "runs = {\n",
    "    'num_vars basic Sphere': [benchmarks.Sphere, 2],\n",
    "    'num_vars more Sphere': [benchmarks.Sphere, 10],\n",
    "    'num_vars basic Rosenbrock': [benchmarks.Rosenbrock, 2],\n",
    "    'num_vars more Rosenbrock': [benchmarks.Rosenbrock, 10],\n",
    "    'num_vars basic Ackley': [benchmarks.Ackley, 2],\n",
    "    'num_vars more Ackley': [benchmarks.Ackley, 10],\n",
    "    'num_vars basic Schwefel': [benchmarks.Schwefel, 2],\n",
    "    'num_vars more Schwefel': [benchmarks.Schwefel, 10],\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "args = {}\n",
    "\n",
    "# common parameters\n",
    "args[\"max_generations\"] = 100 # Number of generations\n",
    "args[\"pop_size\"] = 50 # population size\n",
    "# parameters for the GA\n",
    "args[\"gaussian_stdev\"] = 0.5 # Standard deviation of the Gaussian mutations\n",
    "args[\"mutation_rate\"] = 0.5 # fraction of loci to perform mutation on\n",
    "args[\"tournament_size\"] = 2\n",
    "args[\"num_elites\"] = 1 # number of elite individuals to maintain in each gen\n",
    "# parameters for the ES\n",
    "args[\"num_offspring\"] = 100 #lambda\n",
    "args[\"sigma\"] = 1.0 # default standard deviation\n",
    "args[\"strategy_mode\"] = es.INDIVIDUAL # es.GLOBAL, es.INDIVIDUAL, None\n",
    "args[\"mixing_number\"] = 1 #rho\n",
    "# parameters for the PSO\n",
    "args[\"topology\"] = pso.RING #pso.RING, pso.STAR\n",
    "args[\"neighborhood_size\"] = 5   #used only for the ring topology\n",
    "args[\"inertia\"] = 0.5\n",
    "args[\"cognitive_rate\"] = 2.1\n",
    "args[\"social_rate\"] = 2.1\n",
    "\n",
    "\n",
    "for run in runs:\n",
    "    \n",
    "    print()\n",
    "    print('----------------------------------------------------')\n",
    "    print()\n",
    "    print(run, runs[run])\n",
    "\n",
    "    # the problem class\n",
    "    args[\"problem_class\"] = runs[run][0]\n",
    "    num_vars = runs[run][1] # Number of dimensions of the search space\n",
    "\n",
    "    display = False # Plot initial and final populations\n",
    "\n",
    "    rng = NumpyRandomWrapper()\n",
    "    # Run GA\n",
    "    args[\"fig_title\"] = \"GA\"\n",
    "    best_individual, best_fitness, final_pop = ga.run_ga(rng,num_vars=num_vars,\n",
    "                                            display=display,use_log_scale=True,\n",
    "                                            **args)\n",
    "    ga_fitnesses.append(best_fitness)\n",
    "    print(f\"Best GA fitness : {best_fitness}\")\n",
    "    # Run ES\n",
    "    args[\"fig_title\"] = \"ES\"\n",
    "    best_individual, best_fitness, final_pop = es.run_es(rng,num_vars=num_vars,\n",
    "                                                display=display,use_log_scale=True,\n",
    "                                                **args)\n",
    "    es_fitnesses.append(best_fitness)\n",
    "    print(f\"Best ES fitness : {best_fitness}\")\n",
    "    # Run PSO\n",
    "    args[\"fig_title\"] = \"PSO\"\n",
    "    best_individual, best_fitness, final_pop = pso.run_pso(rng,num_vars=num_vars,\n",
    "                                                display=display,use_log_scale=True,\n",
    "                                                **args)\n",
    "    pso_fitnesses.append(best_fitness)\n",
    "    print(f\"Best PS fitness: {best_fitness}\")\n",
    "\n",
    "    ioff()\n",
    "    show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96ee507",
   "metadata": {},
   "source": [
    "#### cambio parametri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Running: run1 with {'function': <class 'inspyred.benchmarks.Sphere'>, 'num_vars': 10, 'pop_size': 50, 'max_generations': 100}\n",
      "Best GA fitness : 0.24868964404768795\n",
      "Best ES fitness : 0.000276720343761519\n",
      "Best PSO fitness: 0.006474592122361082\n",
      "\n",
      "\n",
      "Running: run2 with {'function': <class 'inspyred.benchmarks.Sphere'>, 'num_vars': 10, 'pop_size': 25, 'max_generations': 200}\n",
      "Best GA fitness : 0.1377845925897828\n",
      "Best ES fitness : 9.717170608445408e-06\n",
      "Best PSO fitness: 0.00021661924735165674\n",
      "\n",
      "\n",
      "Running: run3 with {'function': <class 'inspyred.benchmarks.Sphere'>, 'num_vars': 10, 'pop_size': 100, 'max_generations': 50}\n",
      "Best GA fitness : 0.36746196689187544\n",
      "Best ES fitness : 1.2824281343874615\n",
      "Best PSO fitness: 0.29196956749594777\n",
      "\n",
      "\n",
      "Running: run4 with {'function': <class 'inspyred.benchmarks.Rosenbrock'>, 'num_vars': 10, 'pop_size': 50, 'max_generations': 100}\n",
      "Best GA fitness : 157.89298696579198\n",
      "Best ES fitness : 69.17224973426129\n",
      "Best PSO fitness: 97.94475136197103\n",
      "\n",
      "\n",
      "Running: run5 with {'function': <class 'inspyred.benchmarks.Rosenbrock'>, 'num_vars': 10, 'pop_size': 25, 'max_generations': 200}\n",
      "Best GA fitness : 76.58876473458272\n",
      "Best ES fitness : 4.677630152433637\n",
      "Best PSO fitness: 17.71361495391355\n",
      "\n",
      "\n",
      "Running: run6 with {'function': <class 'inspyred.benchmarks.Rosenbrock'>, 'num_vars': 10, 'pop_size': 100, 'max_generations': 50}\n",
      "Best GA fitness : 55.97489472257644\n",
      "Best ES fitness : 604.7184060307246\n",
      "Best PSO fitness: 329.1866201391654\n",
      "\n",
      "\n",
      "Running: run7 with {'function': <class 'inspyred.benchmarks.Ackley'>, 'num_vars': 10, 'pop_size': 50, 'max_generations': 100}\n",
      "Best GA fitness : 1.8754732913545138\n",
      "Best ES fitness : 1.5337910120914242\n",
      "Best PSO fitness: 4.639020343399753\n",
      "\n",
      "\n",
      "Running: run8 with {'function': <class 'inspyred.benchmarks.Ackley'>, 'num_vars': 10, 'pop_size': 25, 'max_generations': 200}\n",
      "Best GA fitness : 1.501123218142809\n",
      "Best ES fitness : 18.286718496750883\n",
      "Best PSO fitness: 0.6709554974663239\n",
      "\n",
      "\n",
      "Running: run9 with {'function': <class 'inspyred.benchmarks.Ackley'>, 'num_vars': 10, 'pop_size': 100, 'max_generations': 50}\n",
      "Best GA fitness : 2.508185257629045\n",
      "Best ES fitness : 12.588987751453198\n",
      "Best PSO fitness: 6.4949171744392125\n",
      "\n",
      "\n",
      "Running: run10 with {'function': <class 'inspyred.benchmarks.Schwefel'>, 'num_vars': 10, 'pop_size': 50, 'max_generations': 100}\n",
      "Best GA fitness : 1101.0368881370991\n",
      "Best ES fitness : 1292.2424096842642\n",
      "Best PSO fitness: 543.5908718937762\n",
      "\n",
      "\n",
      "Running: run11 with {'function': <class 'inspyred.benchmarks.Schwefel'>, 'num_vars': 10, 'pop_size': 25, 'max_generations': 200}\n",
      "Best GA fitness : 990.855733357756\n",
      "Best ES fitness : 1006.7411464121569\n",
      "Best PSO fitness: 713.6651970820412\n",
      "\n",
      "\n",
      "Running: run12 with {'function': <class 'inspyred.benchmarks.Schwefel'>, 'num_vars': 10, 'pop_size': 100, 'max_generations': 50}\n",
      "Best GA fitness : 266.2221193223877\n",
      "Best ES fitness : 1790.5728075465495\n",
      "Best PSO fitness: 1182.998666996115\n"
     ]
    }
   ],
   "source": [
    "from pylab import *\n",
    "import sys\n",
    "from inspyred import ec\n",
    "from inspyred import benchmarks\n",
    "\n",
    "from utils.utils_06.inspyred_utils import NumpyRandomWrapper\n",
    "import utils.utils_06.ga as ga\n",
    "import utils.utils_06.es as es\n",
    "import utils.utils_06.pso as pso\n",
    "\n",
    "\"\"\"\n",
    "------------------------------------------------------------------------\n",
    "Edit this part to do the exercises\n",
    "------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "# New structure for 'runs'\n",
    "runs = {\n",
    "    'run1': {\"function\": benchmarks.Sphere, \"num_vars\": 10, \"pop_size\": 50, \"max_generations\": 100},\n",
    "    'run2': {\"function\": benchmarks.Sphere, \"num_vars\": 10, \"pop_size\": 25, \"max_generations\": 200},\n",
    "    'run3': {\"function\": benchmarks.Sphere, \"num_vars\": 10, \"pop_size\": 100, \"max_generations\": 50},\n",
    "    'run4': {\"function\": benchmarks.Rosenbrock, \"num_vars\": 10, \"pop_size\": 50, \"max_generations\": 100},\n",
    "    'run5': {\"function\": benchmarks.Rosenbrock, \"num_vars\": 10, \"pop_size\": 25, \"max_generations\": 200},\n",
    "    'run6': {\"function\": benchmarks.Rosenbrock, \"num_vars\": 10, \"pop_size\": 100, \"max_generations\": 50},\n",
    "    'run7': {\"function\": benchmarks.Ackley, \"num_vars\": 10, \"pop_size\": 50, \"max_generations\": 100},\n",
    "    'run8': {\"function\": benchmarks.Ackley, \"num_vars\": 10, \"pop_size\": 25, \"max_generations\": 200},\n",
    "    'run9': {\"function\": benchmarks.Ackley, \"num_vars\": 10, \"pop_size\": 100, \"max_generations\": 50},\n",
    "    'run10': {\"function\": benchmarks.Schwefel, \"num_vars\": 10, \"pop_size\": 50, \"max_generations\": 100},\n",
    "    'run11': {\"function\": benchmarks.Schwefel, \"num_vars\": 10, \"pop_size\": 25, \"max_generations\": 200},\n",
    "    'run12': {\"function\": benchmarks.Schwefel, \"num_vars\": 10, \"pop_size\": 100, \"max_generations\": 50},\n",
    "}\n",
    "\n",
    "# Parameters for GA, ES, and PSO are still defined globally\n",
    "args = {}\n",
    "\n",
    "# parameters for the GA\n",
    "args[\"gaussian_stdev\"] = 0.5  # Standard deviation of the Gaussian mutations\n",
    "args[\"mutation_rate\"] = 0.5   # fraction of loci to perform mutation on\n",
    "args[\"tournament_size\"] = 2\n",
    "args[\"num_elites\"] = 1        # number of elite individuals to maintain in each gen\n",
    "\n",
    "# parameters for the ES\n",
    "args[\"num_offspring\"] = 100   # lambda (offspring)\n",
    "args[\"sigma\"] = 1.0           # default standard deviation\n",
    "args[\"strategy_mode\"] = es.INDIVIDUAL  # es.GLOBAL, es.INDIVIDUAL, None\n",
    "args[\"mixing_number\"] = 1     # rho\n",
    "\n",
    "# parameters for the PSO\n",
    "args[\"topology\"] = pso.RING   # pso.RING, pso.STAR\n",
    "args[\"neighborhood_size\"] = 5  # used only for the ring topology\n",
    "args[\"inertia\"] = 0.5\n",
    "args[\"cognitive_rate\"] = 2.1\n",
    "args[\"social_rate\"] = 2.1\n",
    "\n",
    "# To store results for each combination\n",
    "ga_fitnesses = []\n",
    "es_fitnesses = []\n",
    "pso_fitnesses = []\n",
    "\n",
    "# Loop through different configurations\n",
    "for run_name, run_params in runs.items():\n",
    "    print(f\"\\n\\nRunning: {run_name} with {run_params}\")\n",
    "\n",
    "    # Extract parameters from the dictionary\n",
    "    args[\"problem_class\"] = run_params[\"function\"]\n",
    "    num_vars = run_params[\"num_vars\"]  # Number of dimensions of the search space\n",
    "    args[\"pop_size\"] = run_params[\"pop_size\"]  # Population size\n",
    "    args[\"max_generations\"] = run_params[\"max_generations\"]  # Generations\n",
    "\n",
    "    display = False  # Plot initial and final populations\n",
    "    rng = NumpyRandomWrapper()\n",
    "\n",
    "    # Run GA\n",
    "    args[\"fig_title\"] = \"GA\"\n",
    "    best_individual, best_fitness, final_pop = ga.run_ga(rng, num_vars=num_vars,\n",
    "                                                        display=display, use_log_scale=True,\n",
    "                                                        **args)\n",
    "    ga_fitnesses.append(best_fitness)\n",
    "    print(f\"Best GA fitness : {best_fitness}\")\n",
    "\n",
    "    # Run ES\n",
    "    args[\"fig_title\"] = \"ES\"\n",
    "    best_individual, best_fitness, final_pop = es.run_es(rng, num_vars=num_vars,\n",
    "                                                        display=display, use_log_scale=True,\n",
    "                                                        **args)\n",
    "    es_fitnesses.append(best_fitness)\n",
    "    print(f\"Best ES fitness : {best_fitness}\")\n",
    "\n",
    "    # Run PSO\n",
    "    args[\"fig_title\"] = \"PSO\"\n",
    "    best_individual, best_fitness, final_pop = pso.run_pso(rng, num_vars=num_vars,\n",
    "                                                          display=display, use_log_scale=True,\n",
    "                                                          **args)\n",
    "    pso_fitnesses.append(best_fitness)\n",
    "    print(f\"Best PSO fitness: {best_fitness}\")\n",
    "\n",
    "# Show results\n",
    "ioff()\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf48726",
   "metadata": {},
   "source": [
    "## Instructions and questions\n",
    "\n",
    "Concisely note down your observations from the previous exercises (follow the bullet points) and think about the following questions. \n",
    "\n",
    "- When do you think it is useful to have a lower (higher) cognitive learning rate? What about the social learning rate?\n",
    "- From a biological point of view, which neighborhood topology do you consider as the most plausible?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
